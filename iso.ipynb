{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlynQhH9aXDj",
        "outputId": "fec8d757-31df-480f-fc62-049c6593d4ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc, numpy as np, pickle\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import Input, Bidirectional, GRU, Masking, Dense, Dropout, Lambda, Activation, dot, multiply, concatenate\n",
        "#from keras.layers import TimeDistributed\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "BFGx_kvFbDTz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_text [num of video, max num of utterance = max_utt_len, dim of representation]\n",
        "#train_len: num of utterance in every video\n",
        "(train_text, train_label, test_text, test_label, max_utt_len, train_len, test_len) = pickle.load(open('/content/mytext.pickle', 'rb'))\n",
        "#(train_audio, _, test_audio, _, _, _, _) = pickle.load(open('./input/audio.pickle', 'rb'))\n",
        "\n",
        "#original one\n",
        "#(train_video, _, test_video, _, _, _, _) = pickle.load(open('/content/video.pickle', 'rb'))\n",
        "train_video = pickle.load(open('/content/video_train.pickle','rb'))\n",
        "test_video = pickle.load(open('/content/video_test.pickle','rb'))"
      ],
      "metadata": {
        "id": "i9u4Kk5SeDSH"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = np.concatenate((train_text, test_text[:10]), axis = 0)\n",
        "train_video = np.concatenate((train_video, test_video[:10]), axis = 0)\n",
        "test_text = test_text[10:]\n",
        "test_video = test_video[10:]\n",
        "train_label = np.concatenate((train_label, test_label[:10]), axis = 0)\n",
        "test_label = test_label[10:]\n",
        "train_len = train_len + test_len[:10]\n",
        "test_len = test_len[10:]"
      ],
      "metadata": {
        "id": "N3iIcaLcTDBg"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mask zero value to speed up\n",
        "\n",
        "def create_mask(train_data, test_data, train_length, test_length):\n",
        "    '''\n",
        "    # Arguments\n",
        "        train, test data (any one modality (text, audio or video)), utterance lengths in train, test videos\n",
        "    # Returns\n",
        "        mask for train and test data\n",
        "    '''\n",
        "\n",
        "    train_mask = np.zeros((train_data.shape[0], train_data.shape[1]), dtype='float')\n",
        "    for i in range(len(train_length)):\n",
        "        train_mask[i, :train_length[i]] = 1.0\n",
        "\n",
        "    test_mask = np.zeros((test_data.shape[0], test_data.shape[1]), dtype='float')\n",
        "    for i in range(len(test_length)):\n",
        "        test_mask[i, :test_length[i]] = 1.0\n",
        "    \n",
        "    return train_mask, test_mask"
      ],
      "metadata": {
        "id": "jLKpqUTQqoPI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask, test_mask = create_mask(train_text, test_text, train_len, test_len)"
      ],
      "metadata": {
        "id": "h8caEKKGry7o"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bi_modal_attention(x, y): #x=V, y=T\n",
        "  m1 = dot([x, y], axes=(2, 2)) # m1 = x dot y^T, axis=0:batch size, axis=1: max_len, axis=2:dim of representation\n",
        "  m2 = dot([y, x], axes=(2, 2)) # m2 = y dot x^T\n",
        "\n",
        "  n1 = Activation('softmax')(m1) # n1 = softmax(m1)\n",
        "  n2 = Activation('softmax')(m2)\n",
        "\n",
        "  o1 = dot([n1, y], axes=(2, 1)) #o1 = n1 dot y\n",
        "  o2 = dot([n2, x], axes=(2, 1))\n",
        "\n",
        "  a1 =  multiply([o1, x]) # a1 = o1 element-wise multiply x\n",
        "  a2 =  multiply([o2, y])\n",
        "\n",
        "  return concatenate([a1, a2])"
      ],
      "metadata": {
        "id": "EFE4v4QApiBW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MMMUBA():\n",
        "  #Initialise the keras tensor\n",
        "  text = Input(shape=(train_text.shape[1], train_text.shape[2]))\n",
        "  video = Input(shape=(train_video.shape[1], train_video.shape[2]))\n",
        "\n",
        "  #mask layer\n",
        "  masked_text = Masking(mask_value=0)(text)\n",
        "  masked_video = Masking(mask_value=0)(video)\n",
        "\n",
        "\n",
        "  #RNN\n",
        "  drop_rnn = 0.5\n",
        "  gru_units = 300\n",
        "            \n",
        "  rnn_text = Bidirectional(GRU(gru_units, return_sequences=True, dropout=0.5, recurrent_dropout=0.5), merge_mode='concat')(masked_text)\n",
        "  rnn_video = Bidirectional(GRU(gru_units, return_sequences=True, dropout=0.5, recurrent_dropout=0.5), merge_mode='concat')(masked_video)        \n",
        "            \n",
        "  rnn_text = Dropout(drop_rnn)(rnn_text)\n",
        "  rnn_video = Dropout(drop_rnn)(rnn_video)\n",
        "\n",
        "  #no longer need time-distributed layer\n",
        "  drop_dense = 0.5\n",
        "  dense_units = 100\n",
        "\n",
        "  dense_text = Dropout(drop_dense)(Dense(dense_units, activation='tanh')(rnn_text))\n",
        "  dense_video = Dropout(drop_dense)(Dense(dense_units, activation='tanh')(rnn_video))\n",
        "  \n",
        "  #dense_text: [None, max num of utterance = max_utt_len, dim of representation]\n",
        "\n",
        "  #Attention layer:\n",
        "  vt_att = bi_modal_attention(dense_video, dense_text)\n",
        "\n",
        "  #concat v and t:\n",
        "  merged = concatenate([vt_att, dense_video, dense_text])\n",
        "\n",
        "\n",
        "  #output:\n",
        "  output = Dense(2, activation='softmax')(merged)\n",
        "  #print(output[0][0])\n",
        "  #model:\n",
        "  model = Model([text, video], output)  \n",
        "  return model"
      ],
      "metadata": {
        "id": "LXTx-p4Sak0-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MMMUBA()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpUf4AIf1Ht5",
        "outputId": "dd80f1be-a228-470d-d698-9367d4e0715b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7f85a4543700>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_test_result(result, test_label, test_mask):\n",
        "    '''\n",
        "    # Arguments\n",
        "        predicted test labels, gold test labels and test mask\n",
        "    # Returns\n",
        "        accuracy of the predicted labels\n",
        "    '''\n",
        "    true_label=[]\n",
        "    predicted_label=[]\n",
        "\n",
        "    for i in range(result.shape[0]):\n",
        "        for j in range(result.shape[1]):\n",
        "            if test_mask[i,j]==1:\n",
        "                true_label.append(np.argmax(test_label[i,j] )) #np.argmax returns [0.9, 0.1] as 0 and [0.1, 0.9] as 1\n",
        "                                                              # it is more efficient to calculate the accuracy\n",
        "                predicted_label.append(np.argmax(result[i,j] ))\n",
        "  \n",
        "    return accuracy_score(true_label, predicted_label)\n"
      ],
      "metadata": {
        "id": "8rhpWNq1xKhN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reason for this function: We use softmax to category and we need to compute the accuracy \n",
        "# thus we need to make the [1] and [0] as [1,0] and [0,1]\n",
        "def create_one_hot_labels(train_label, test_label):\n",
        "    '''\n",
        "    # Arguments\n",
        "        train and test labels (2D matrices)\n",
        "    # Returns\n",
        "        one hot encoded train and test labels (3D matrices)\n",
        "    '''\n",
        "\n",
        "    maxlen = int(max(train_label.max(), test_label.max()))\n",
        "    \n",
        "    train = np.zeros((train_label.shape[0], train_label.shape[1], maxlen+1))\n",
        "    test = np.zeros((test_label.shape[0], test_label.shape[1], maxlen+1))\n",
        "    \n",
        "    for i in range(train_label.shape[0]):\n",
        "        for j in range(train_label.shape[1]):\n",
        "            train[i,j,train_label[i,j]] = 1\n",
        "\n",
        "    for i in range(test_label.shape[0]):\n",
        "        for j in range(test_label.shape[1]):\n",
        "            test[i,j,test_label[i,j]] = 1\n",
        "\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "beMAHGBu4StL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_label, test_label = create_one_hot_labels(train_label.astype('int'), test_label.astype('int'))"
      ],
      "metadata": {
        "id": "Km5lr-Yd4x70"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ4GSTdtBA1X",
        "outputId": "9e37c250-aa03-4fca-f647-72d3c47b3caf"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(71, 63, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "310VJ8NG5ePV",
        "outputId": "98a5488d-e838-4868-f200-a7c73bd183bd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(71, 63)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "\n",
        "  accuracy = []\n",
        "\n",
        "  model = MMMUBA()\n",
        "  #lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "   # [5,23],\n",
        "    #[1e-2,1e-3,1e-4])\n",
        "  opt = tf.keras.optimizers.Adamax(learning_rate=1e-3, weight_decay=1e-5)\n",
        "  model.compile(optimizer= opt, loss='categorical_crossentropy', weighted_metrics=[], sample_weight_mode='temporal', metrics=['accuracy'])\n",
        "\n",
        "  path = '/content/model.hdf5'\n",
        "  #callbacks\n",
        "  early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=0)\n",
        "  check = ModelCheckpoint(path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=0)\n",
        "\n",
        "  history = model.fit([train_text, train_video], train_label,\n",
        "                            epochs=50,\n",
        "                            batch_size=8,\n",
        "                            sample_weight=train_mask, #weight is 0 for none value\n",
        "                            shuffle=True, \n",
        "                            callbacks=[early_stop, check],\n",
        "                            # directly use test as validation set\n",
        "                            validation_data=([test_text, test_video], test_label, test_mask),\n",
        "                            verbose=1)\n",
        "  \n",
        "  model.load_weights(path)\n",
        "  test_predictions = model.predict([test_text, test_video])\n",
        "  print(test_predictions[0][0])\n",
        "  test_accuracy = calc_test_result(test_predictions, test_label, test_mask)\n",
        "  accuracy.append(test_accuracy)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "_m0wgo1QvWIH"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aaa = train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGmF3vJ6uURV",
        "outputId": "aa55c2bd-bebd-42e1-fc59-0f07bbbfab72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "2/2 [==============================] - 18s 4s/step - loss: 0.3534 - accuracy: 0.5543 - val_loss: 0.2036 - val_accuracy: 0.7301\n",
            "Epoch 2/15\n",
            "2/2 [==============================] - 5s 3s/step - loss: 0.2061 - accuracy: 0.7395 - val_loss: 0.1812 - val_accuracy: 0.7606\n",
            "Epoch 3/15\n",
            "2/2 [==============================] - 7s 3s/step - loss: 0.1446 - accuracy: 0.8362 - val_loss: 0.1768 - val_accuracy: 0.7713\n",
            "Epoch 4/15\n",
            "2/2 [==============================] - 5s 3s/step - loss: 0.1159 - accuracy: 0.8742 - val_loss: 0.1791 - val_accuracy: 0.7832\n",
            "Epoch 5/15\n",
            "2/2 [==============================] - 5s 3s/step - loss: 0.0878 - accuracy: 0.8984 - val_loss: 0.1848 - val_accuracy: 0.7846\n",
            "Epoch 6/15\n",
            "2/2 [==============================] - 5s 3s/step - loss: 0.0718 - accuracy: 0.9267 - val_loss: 0.1926 - val_accuracy: 0.7872\n",
            "Epoch 7/15\n",
            "2/2 [==============================] - 5s 3s/step - loss: 0.0568 - accuracy: 0.9419 - val_loss: 0.2020 - val_accuracy: 0.7859\n",
            "Epoch 8/15\n",
            "2/2 [==============================] - 5s 3s/step - loss: 0.0476 - accuracy: 0.9565 - val_loss: 0.2119 - val_accuracy: 0.7886\n",
            "Epoch 9/15\n",
            "2/2 [==============================] - 5s 3s/step - loss: 0.0455 - accuracy: 0.9585 - val_loss: 0.2222 - val_accuracy: 0.7912\n",
            "Epoch 10/15\n",
            "2/2 [==============================] - 5s 3s/step - loss: 0.0392 - accuracy: 0.9703 - val_loss: 0.2325 - val_accuracy: 0.7939\n",
            "Epoch 11/15\n",
            "2/2 [==============================] - 5s 3s/step - loss: 0.0334 - accuracy: 0.9710 - val_loss: 0.2425 - val_accuracy: 0.7926\n",
            "Epoch 12/15\n",
            "2/2 [==============================] - 5s 3s/step - loss: 0.0312 - accuracy: 0.9730 - val_loss: 0.2522 - val_accuracy: 0.7939\n",
            "Epoch 13/15\n",
            "2/2 [==============================] - 5s 3s/step - loss: 0.0278 - accuracy: 0.9744 - val_loss: 0.2615 - val_accuracy: 0.7899\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "[0.9984988  0.00150112]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aaa\n",
        "#paper: 81.51"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MawTPVUH9IJg",
        "outputId": "ccdc1398-41da-43c1-c043-4192bf047735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7938829787234043]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#time: 21:41"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7Em1xWT-omK",
        "outputId": "31fdeb52-c743-4fce-d07d-3f81dba6fba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bbb = train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cee3GVto-W9m",
        "outputId": "30b15537-8aae-4310-8852-413d7b865da1"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 36s 3s/step - loss: 0.7971 - accuracy: 0.5195 - val_loss: 0.7267 - val_accuracy: 0.4893\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 21s 2s/step - loss: 0.7898 - accuracy: 0.5271 - val_loss: 0.7029 - val_accuracy: 0.5598\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.7306 - accuracy: 0.5475 - val_loss: 0.7016 - val_accuracy: 0.5363\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 20s 2s/step - loss: 0.7255 - accuracy: 0.5598 - val_loss: 0.6971 - val_accuracy: 0.5449\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.7221 - accuracy: 0.5469 - val_loss: 0.6898 - val_accuracy: 0.5705\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.7253 - accuracy: 0.5405 - val_loss: 0.6816 - val_accuracy: 0.5726\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 20s 2s/step - loss: 0.7098 - accuracy: 0.5720 - val_loss: 0.6784 - val_accuracy: 0.5577\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.6876 - accuracy: 0.5872 - val_loss: 0.6760 - val_accuracy: 0.5556\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.7004 - accuracy: 0.5732 - val_loss: 0.6845 - val_accuracy: 0.5748\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 21s 2s/step - loss: 0.7011 - accuracy: 0.5714 - val_loss: 0.6766 - val_accuracy: 0.5598\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.6857 - accuracy: 0.5784 - val_loss: 0.6713 - val_accuracy: 0.5684\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 18s 2s/step - loss: 0.6783 - accuracy: 0.5924 - val_loss: 0.6655 - val_accuracy: 0.5748\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 20s 2s/step - loss: 0.6818 - accuracy: 0.5918 - val_loss: 0.6665 - val_accuracy: 0.5833\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 18s 2s/step - loss: 0.6864 - accuracy: 0.5627 - val_loss: 0.6588 - val_accuracy: 0.5769\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.6763 - accuracy: 0.5889 - val_loss: 0.6550 - val_accuracy: 0.5962\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 20s 2s/step - loss: 0.6830 - accuracy: 0.5883 - val_loss: 0.6532 - val_accuracy: 0.6047\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 18s 2s/step - loss: 0.6554 - accuracy: 0.6198 - val_loss: 0.6491 - val_accuracy: 0.5919\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 22s 3s/step - loss: 0.6596 - accuracy: 0.6076 - val_loss: 0.6528 - val_accuracy: 0.5962\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.6556 - accuracy: 0.6192 - val_loss: 0.6511 - val_accuracy: 0.5897\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.6414 - accuracy: 0.6216 - val_loss: 0.6477 - val_accuracy: 0.6004\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 22s 2s/step - loss: 0.6445 - accuracy: 0.6379 - val_loss: 0.6416 - val_accuracy: 0.6004\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 18s 2s/step - loss: 0.6245 - accuracy: 0.6478 - val_loss: 0.6379 - val_accuracy: 0.6154\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 18s 2s/step - loss: 0.6382 - accuracy: 0.6426 - val_loss: 0.6305 - val_accuracy: 0.6389\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 21s 2s/step - loss: 0.6423 - accuracy: 0.6356 - val_loss: 0.6405 - val_accuracy: 0.6282\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.6331 - accuracy: 0.6338 - val_loss: 0.6353 - val_accuracy: 0.6261\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.6296 - accuracy: 0.6397 - val_loss: 0.6348 - val_accuracy: 0.6197\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 21s 2s/step - loss: 0.6373 - accuracy: 0.6472 - val_loss: 0.6406 - val_accuracy: 0.6346\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 18s 2s/step - loss: 0.6150 - accuracy: 0.6536 - val_loss: 0.6324 - val_accuracy: 0.6346\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.6368 - accuracy: 0.6402 - val_loss: 0.6318 - val_accuracy: 0.6325\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 20s 2s/step - loss: 0.6331 - accuracy: 0.6455 - val_loss: 0.6244 - val_accuracy: 0.6432\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.6259 - accuracy: 0.6571 - val_loss: 0.6279 - val_accuracy: 0.6325\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.6191 - accuracy: 0.6513 - val_loss: 0.6188 - val_accuracy: 0.6517\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 20s 2s/step - loss: 0.6299 - accuracy: 0.6589 - val_loss: 0.6191 - val_accuracy: 0.6325\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 18s 2s/step - loss: 0.6231 - accuracy: 0.6676 - val_loss: 0.6189 - val_accuracy: 0.6389\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 20s 2s/step - loss: 0.6164 - accuracy: 0.6641 - val_loss: 0.6143 - val_accuracy: 0.6538\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.6198 - accuracy: 0.6513 - val_loss: 0.6224 - val_accuracy: 0.6538\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 18s 2s/step - loss: 0.6096 - accuracy: 0.6665 - val_loss: 0.6163 - val_accuracy: 0.6474\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 20s 2s/step - loss: 0.6111 - accuracy: 0.6706 - val_loss: 0.6376 - val_accuracy: 0.6325\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.6103 - accuracy: 0.6606 - val_loss: 0.6207 - val_accuracy: 0.6282\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 18s 2s/step - loss: 0.5882 - accuracy: 0.6834 - val_loss: 0.6282 - val_accuracy: 0.6410\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 20s 2s/step - loss: 0.5973 - accuracy: 0.6735 - val_loss: 0.6230 - val_accuracy: 0.6496\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.5827 - accuracy: 0.6950 - val_loss: 0.6168 - val_accuracy: 0.6389\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.5967 - accuracy: 0.6717 - val_loss: 0.6564 - val_accuracy: 0.6026\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 21s 2s/step - loss: 0.6183 - accuracy: 0.6548 - val_loss: 0.6177 - val_accuracy: 0.6432\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 19s 2s/step - loss: 0.5885 - accuracy: 0.6834 - val_loss: 0.6212 - val_accuracy: 0.6474\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "[0.36904162 0.6309584 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bbb"
      ],
      "metadata": {
        "id": "uRZZ4n2bBjAW",
        "outputId": "05740b78-f92a-44ba-acba-36304a6ea600",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6538461538461539]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(test_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLR6NUf_SY8b",
        "outputId": "79998d3a-a5c8-4a94-9409-bf3379916adc"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "468"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(train_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENywCRZESpfs",
        "outputId": "6c6973a6-6cc0-470d-d7c2-9ad2e6bed941"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1716"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    }
  ]
}